{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Daily Challenge: Simplified Self-Attention Explained"
      ],
      "metadata": {
        "id": "nePtjiyppHpD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task\n",
        "1. Simplified self-attention\n",
        "\n",
        "We implement a simplified variant of self-attention, free from any trainable waights. the goal of this section to illustrate a few key consetps in self attention before adding trainable weights.\n",
        "\n",
        " - Load Input Tensor (Word Embeddings):\n",
        "    - Start with numerical representations of words (embeddings) because neural networks process numbers. This is the input data our self-attention mechanism will work on.\n"
      ],
      "metadata": {
        "id": "-E3MR92OpLQ_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "gSLMH4Bjo-hQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "inputs = torch.tensor(\n",
        "[\n",
        "    [0.43, 0.15, 0.89], # your\n",
        "    [0.55, 0.87, 0.66], # journey\n",
        "    [0.57, 0.85, 0.64], # starts\n",
        "    [0.22, 0.58, 0.33], # with\n",
        "    [0.77, 0.25, 0.10], # one\n",
        "    [0.05, 0.80, 0.55] # step\n",
        "]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- Select a Query Vector:\n",
        "  - In self-attention, we compare each word (vector) against others to understand their relationships. The “query” is the word we’re currently focusing on.\n",
        "- 1.1 Computing Attention Weights for Inputs[2]:\n",
        "  - 1.1.1 Attention Score:\n",
        "      The dot product measures how similar two vectors are. Higher scores indicate greater similarity. We’re finding how relevant each word is to our “query” word.\n"
      ],
      "metadata": {
        "id": "6GRxm3kop2zF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = inputs[2]\n",
        "attn_scores_2 = torch.empty(inputs.shape[0])\n",
        "for i, x_i in enumerate(inputs):\n",
        "  print(x_i)\n",
        "  attn_scores_2[i] = torch.dot(x_i, query)\n",
        "print(attn_scores_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5Bbo-nNv6EZ",
        "outputId": "9946ec3f-05e4-4552-977f-fb97ea21fdd2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.4300, 0.1500, 0.8900])\n",
            "tensor([0.5500, 0.8700, 0.6600])\n",
            "tensor([0.5700, 0.8500, 0.6400])\n",
            "tensor([0.2200, 0.5800, 0.3300])\n",
            "tensor([0.7700, 0.2500, 0.1000])\n",
            "tensor([0.0500, 0.8000, 0.5500])\n",
            "tensor([0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 1.1.2 Attention Weights:\n",
        "\n",
        "  - Softmax transforms the scores into probabilities (attention weights). These weights represent how much “attention” each word should receive when we create the context vector.\n",
        "\n"
      ],
      "metadata": {
        "id": "xTc5R5garEVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "attn_weights_2 = F.softmax(attn_scores_2, dim = 0)\n",
        "print(attn_weights_2)"
      ],
      "metadata": {
        "id": "muVxGcc7rEED",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7a90484-129e-435d-b07f-184e72272833"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 1.1.3 Context Vector:\n",
        "\n",
        "    The context vector is a weighted sum of the input vectors. It represents a refined version of the query, incorporating information from other relevant words.\n",
        "\n"
      ],
      "metadata": {
        "id": "xcMu3CVa1Is-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context_vector_2 = torch.sum(attn_weights_2.unsqueeze(1) * inputs, dim=0)\n",
        "context_vector_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FmNw9nf2fs4",
        "outputId": "3646e4d0-5078-42b1-9921-ffa6d19299c0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4431, 0.6496, 0.5671])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 1.2 Computing Attention Weights for All Inputs:\n",
        "\n",
        "    - 1.2.1 Attention Score:\n",
        "        - Extend the process to compute attention scores for every word against every other word in the sequence. This creates a matrix of relationships.\n",
        "\n"
      ],
      "metadata": {
        "id": "l-jkj3tFLuBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores = inputs @ inputs.T"
      ],
      "metadata": {
        "id": "2lFYoxQQMIQ-"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60pAtqGyMOVK",
        "outputId": "7fc4d65b-d9a9-4e69-e2ae-45741e86a4f9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
              "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
              "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
              "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
              "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
              "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 1.2.2 Attention Weights:\n",
        "\n",
        "  - Apply softmax across rows to get attention weights for each word, showing its relationship to all others.\n",
        "\n"
      ],
      "metadata": {
        "id": "wS1s8QazMhzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights = F.softmax(attn_scores, dim=1)\n",
        "attn_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4F-gfjNdMkPN",
        "outputId": "5927fbea-bc09-4a26-a378-ebac34f3b561"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
              "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
              "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
              "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
              "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
              "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 1.2.3 All Context Vector:\n",
        "   - Generate a context vector for each word, capturing its meaning in the context of the entire sequence.\n",
        "\n"
      ],
      "metadata": {
        "id": "U3YQcxEkM78v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context_vectors = attn_weights @ inputs\n",
        "context_vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGGhw_CFM7VF",
        "outputId": "e9527930-4fbc-47e0-ba57-71831d1a185a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4421, 0.5931, 0.5790],\n",
              "        [0.4419, 0.6515, 0.5683],\n",
              "        [0.4431, 0.6496, 0.5671],\n",
              "        [0.4304, 0.6298, 0.5510],\n",
              "        [0.4671, 0.5910, 0.5266],\n",
              "        [0.4177, 0.6503, 0.5645]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. The ‘Self’ in Self-Attention\n",
        "\n",
        "In self-attention, the ‘self’ refers to the mechanism’s ability to computer attention weights by relating different positions within a single input sequence.\n",
        "\n",
        "- 2.1 Weights Parameters vs Attention Weights\n",
        "\n",
        "In the weight matrices W, the term ‘weight’ is short for ‘weight parameters’, the values of a neural network that are optimized during training. This is not to be confused with the attention weights.\n",
        "\n",
        "As I already saw in the previous section, attention weights determine the extent to which a context vector depends on the different parts of input, i.e., to what extent the network focuses on different parts of the input.\n",
        "\n",
        "In summary, weight parameters are the fundamental, learnt coefficents that defined the networks connection, while attention weights are dynamic, context specific values.\n",
        "\n",
        "- 2.1 Weights Parameters vs Attention Weights:\n",
        "\n",
        "  - Distinguish between learnt parameters (weights of the network) and dynamically computed attention weights. This clarifies the different roles they play.\n",
        "\n"
      ],
      "metadata": {
        "id": "McrgRtB5NRqx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 2.2 Computing Weight Parameters for Inputs[2]:\n",
        "\n",
        "    - 2.2.1 Initialize the three weight matrices Wq, Wk, Wv:\n",
        "        - Introduce learnable weight matrices (Wq, Wk, Wv) to transform input vectors into queries, keys, and values. This adds flexibility and allows the model to learn complex relationships.\n",
        "\n"
      ],
      "metadata": {
        "id": "KYAN4Ss6Nv-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 3\n",
        "hidden_dim = 4\n",
        "Wq = torch.nn.Parameter(torch.randn(embed_dim, hidden_dim))\n",
        "Wk = torch.nn.Parameter(torch.randn(embed_dim, hidden_dim))\n",
        "Wv = torch.nn.Parameter(torch.randn(embed_dim, hidden_dim))"
      ],
      "metadata": {
        "id": "UtjXq36SNEDp"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 2.2.2 Compute the query, key, and value vectors for inputs[1]:\n",
        "\n",
        "    - These transformations project the input into different “spaces” that emphasize different aspects of the word’s meaning.\n",
        "\n"
      ],
      "metadata": {
        "id": "t4uHCNE3N9k4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = inputs[1]\n",
        "q = x @ Wq\n",
        "k = inputs @ Wk\n",
        "v = inputs @ Wv"
      ],
      "metadata": {
        "id": "OFSa1TA2OBHn"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 2.2.3 Compute the Attention Score inputs[1][1] or ω11:\n",
        "\n",
        "  - Calculate the similarity between the transformed query and key.\n",
        "\n"
      ],
      "metadata": {
        "id": "CrkCzaOLOf6d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 2.2.4 Compute all the Attention Scores for inputs[1]:\n",
        "\n",
        "    - Calculate all the similarity scores against the query vector.\n",
        "\n",
        "- 2.2.5 Attention weights for inputs[1]:\n",
        "\n",
        "    - Normalize the attention scores.\n",
        "\n"
      ],
      "metadata": {
        "id": "kqHajqbXOyj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores = q @ k.T\n",
        "attn_weights_1 = F.softmax(scores, dim=0)\n",
        "attn_weights_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ds9-pBC2Ojg7",
        "outputId": "b3addd7e-21e4-436f-f154-aab0652d899b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2008, 0.1944, 0.1868, 0.1374, 0.0724, 0.2082],\n",
              "       grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 2.2.6 Calculate Context vector for inputs[1]:\n",
        "   - Generate the context vector.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ej_mYWmSTYJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context_vector_1 = attn_weights_1 @ v\n",
        "context_vector_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qH5eakJ2TXXZ",
        "outputId": "f5261a44-f503-4d46-8b3e-d15d1560d6da"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.7491, -0.7984, -0.1104, -0.2245], grad_fn=<SqueezeBackward4>)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 2.3 Computing Weight Parameters for All Inputs:\n",
        "\n",
        "    - 2.3.2 Compute the query, key, and value vectors:\n",
        "        Compute the transformed vectors for all input words.\n",
        "    - 2.3.3 Compute the Attention Score for all inputs:\n",
        "        Compute all attention scores between all words.\n",
        "    - 2.3.4 Attention weights for all inputs:\n",
        "        Normalize the attention scores.\n",
        "    - 2.3.5 Calculate Context vector for all inputs:\n",
        "        Generate all context vectors.\n",
        "\n"
      ],
      "metadata": {
        "id": "bp-EAuoUTeX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Q = inputs @ Wq\n",
        "K = inputs @ Wk\n",
        "V = inputs @ Wv"
      ],
      "metadata": {
        "id": "EdBzA2YkUFDk"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_all = Q @ K.T\n",
        "scores_all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IMQs0cYUMB5",
        "outputId": "574f8807-ca3b-4b91-9cf6-b54278a13182"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.9402,  2.3164,  2.2994,  1.3546,  1.3448,  1.5989],\n",
              "        [-0.2136,  1.7952,  1.8464,  1.0161,  2.2483,  0.5811],\n",
              "        [-0.1998,  1.7890,  1.8424,  1.0038,  2.2846,  0.5480],\n",
              "        [-0.3237,  0.7767,  0.8054,  0.4578,  1.0953,  0.2049],\n",
              "        [ 0.1070,  1.1745,  1.2519,  0.5000,  2.2938, -0.2021],\n",
              "        [-0.4544,  0.9136,  0.9231,  0.6198,  0.8321,  0.5544]],\n",
              "       grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights_all = F.softmax(scores_all, dim=1)\n",
        "weights_all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCFuU7-eUn3_",
        "outputId": "4877b7fa-3404-4175-a5ad-9f7ffdb5c85f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0725, 0.2870, 0.2822, 0.1097, 0.1086, 0.1400],\n",
              "        [0.0297, 0.2214, 0.2331, 0.1016, 0.3484, 0.0658],\n",
              "        [0.0299, 0.2184, 0.2304, 0.0996, 0.3585, 0.0631],\n",
              "        [0.0662, 0.1989, 0.2047, 0.1446, 0.2735, 0.1123],\n",
              "        [0.0550, 0.1600, 0.1729, 0.0815, 0.4901, 0.0404],\n",
              "        [0.0550, 0.2160, 0.2181, 0.1610, 0.1991, 0.1508]],\n",
              "       grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_all = weights_all @ V\n",
        "context_all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GGhFTvnUvn5",
        "outputId": "21ffc82a-c5c8-4370-db2f-be3bcacb0194"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.4007,  1.8906, -1.5530,  1.6846],\n",
              "        [-1.1126,  1.7207, -1.2679,  1.7130],\n",
              "        [-1.1010,  1.7136, -1.2554,  1.7134],\n",
              "        [-1.1643,  1.7008, -1.3060,  1.6205],\n",
              "        [-0.9365,  1.5894, -1.0687,  1.6790],\n",
              "        [-1.2475,  1.7444, -1.4000,  1.6056]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    }
  ]
}