{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab6c1246",
   "metadata": {},
   "source": [
    "# Exercises XP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24415444",
   "metadata": {},
   "source": [
    " ### Exercise 1 : Small Quizz\n",
    "\n",
    "1. What is the key difference between traditional machine learning and deep learning?\n",
    "2. How do artificial neural networks (ANNs) mimic the human brain?\n",
    "3. Why does deep learning perform better on large datasets compared to traditional machine learning?\n",
    "4. What are some challenges of deep learning, and how can they be addressed?\n",
    "5. What is feature engineering, and why is it not needed in deep learning?\n",
    "6. What role do hidden layers play in a deep learning model?\n",
    "7. In an artificial neural network (ANN), what is the function of an activation function?\n",
    "____________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6930877",
   "metadata": {},
   "source": [
    "1. Machine learning is more explicitly used as a means to extract knowledge from data through simpler methods such as decision trees or linear regression, while deep learning uses the more advanced methods found in artificial neural networks.\n",
    "\n",
    "2. The ANNs mimic the human brain by using artificial neurons (nodes) connected by weighted links, used to predict an outcome.\n",
    "\n",
    "3. Deep learning performs better on large datasets because it can automatically learn complex, hierarchical features from the data, whereas traditional machine learning often requires manual feature engineering and struggles with high-dimensional data.\n",
    "\n",
    "4. Some challenges of deep learning are its high computational cost, high data requirement and lack of interpretability. To address these issues one can:  \n",
    "  - Use cloud AI services instead of buying GPUs and optimize models using pruning, quantization, and knowledge distillation.\n",
    "  - Use data augmentation, transfer learning, or unsupervised learning and use pre-trained models or synthetic data generation.\n",
    "  - Use Explainable AI tools and implement attention mechanisms or hybrid models combining deep learning with interpretable techniques,\n",
    "  \n",
    "respectively.\n",
    "\n",
    "5. Feature engineering is the process of manually selecting, transforming, or creating input features from raw data to improve the performance of traditional machine learning models. It is not needed in deep learning because deep neural networks can automatically learn relevant features directly from the raw data through multiple layers of abstraction.\n",
    "\n",
    "6. Hidden layers in a deep learning model transform the input data into progressively more abstract features, allowing the model to learn complex patterns and relationships at different levels of abstraction.\n",
    "\n",
    "7. The activaction function is used to determine whether a neuron should be “activated” (answer: yes) or not (answer: no) based on the weighted sum of inputs. It can also return a number between 0 to 1 indicating a range closer to \"yes\" or \"no\" instead of a binary answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fa271b",
   "metadata": {},
   "source": [
    "### Exercise 2 : Building a Simple Perceptron Decision System\n",
    "\n",
    "You will manually create a simple perceptron-based decision system to determine whether you should go outside based on two inputs:\n",
    "\n",
    "    Temperature (°F)\n",
    "    Rainy (Yes = 1, No = 0)\n",
    "\n",
    "You will assign weights, compute the weighted sum, apply an activation function, and determine the final decision.\n",
    "\n",
    "    Temperature weight = 0.6\n",
    "    Rain weight = 0.4\n",
    "    Bias = 2\n",
    "\n",
    "Compute the weighted sum using the formula:\n",
    "\n",
    "    Weighted Sum=(Temperature×0.6)+(Rain×0.4)+Bias\n",
    "\n",
    "Apply a Step Activation Function:\n",
    "\n",
    "    If Weighted Sum > 20, output 1 (Yes, go outside)\n",
    "    If Weighted Sum ≤ 20, output 0 (No, stay inside)\n",
    "\n",
    "1. Calculate the output for the following conditions:\n",
    "\n",
    "    Case 1: Temperature = 70°F, Rain = 0 (No)\n",
    "    \n",
    "    Case 2: Temperature = 50°F, Rain = 1 (Yes)\n",
    "    \n",
    "\n",
    "2. Interpret the results: Did the perceptron suggest going outside in both cases? Why or why not?\n",
    "_____________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da472f81",
   "metadata": {},
   "source": [
    "Case 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d6cd385",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = 70\n",
    "rain = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41b4d97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = 0.6\n",
    "w2 = 0.4\n",
    "b = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd83a3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_sum = temp*w1 + rain*w2 + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65ce950d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted sum: 44.0\n",
      "Yes, go outside\n"
     ]
    }
   ],
   "source": [
    "print(f\"Weighted sum: {weighted_sum}\")\n",
    "if weighted_sum > 20:\n",
    "    output = 1\n",
    "    print(\"Yes, go outside\")\n",
    "else:\n",
    "    output = 0\n",
    "    pring(\"No, stay inside\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad85ad6e",
   "metadata": {},
   "source": [
    "Case 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e922d1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = 50\n",
    "rain = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f808826",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = 0.6\n",
    "w2 = 0.4\n",
    "b = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afc5ff49",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_sum = temp*w1 + rain*w2 + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4aa581bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted sum: 32.4\n",
      "Yes, go outside\n"
     ]
    }
   ],
   "source": [
    "print(f\"Weighted sum: {weighted_sum}\")\n",
    "if weighted_sum > 20:\n",
    "    output = 1\n",
    "    print(\"Yes, go outside\")\n",
    "else:\n",
    "    output = 0\n",
    "    pring(\"No, stay inside\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04449cd5",
   "metadata": {},
   "source": [
    "The perceptron suggested going outside in both cases because of the threshold and weight chosen for each feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9c9ec2",
   "metadata": {},
   "source": [
    "### Exercise 3 : Building a Simple Neural Network with TensorFlow/Keras\n",
    "\n",
    "Build a simple neural network using TensorFlow/Keras to classify handwritten digits from the MNIST dataset. The network should have:\n",
    "\n",
    "   - One input layer.\n",
    "   - One hidden layer with 128 neurons and ReLU activation.\n",
    "   - One output layer with 10 neurons (for 10 classes) and softmax activation.\n",
    "\n",
    "### Exercise 6 : Visualizing Predictions on the MNIST Dataset\n",
    "\n",
    "Train a simple neural network using TensorFlow/Keras on the MNIST dataset. After training, visualize some of the predictions made by the model.\n",
    "Dataset: The MNIST dataset is included in TensorFlow/Keras.\n",
    "\n",
    "Here are the steps for this exercise :\n",
    "\n",
    "   - Load the MNIST dataset\n",
    "   - Normalize the data\n",
    "   - One-hot encode the labels\n",
    "   - Build the model\n",
    "   - Compile the model\n",
    "   - Train the model\n",
    "   - Make predictions\n",
    "   - Visualize some predictions\n",
    "\n",
    "\n",
    "___________________\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fff4acaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\julie\\anaconda3\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.11.0 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.12.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.21.2)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.2.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (25.2.10)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.62.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\julie\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (21.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\julie\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (58.0.4)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.6)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: cached-property in c:\\users\\julie\\anaconda3\\lib\\site-packages (from h5py>=2.9.0->tensorflow-intel==2.11.0->tensorflow) (1.5.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.38.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\julie\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d648809f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b24e439",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_data, y_train_data), (x_val_data, y_val_data) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b08d904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_function(x_new, y_new):\n",
    "  x_new = tf.cast(x_new, tf.float32) / 255.0  # Normalize pixel values\n",
    "  y_new = tf.cast(y_new, tf.int64)            # Convert labels to integers\n",
    "  return x_new, y_new\n",
    "\n",
    "def func_creating_dataset(xs_data, ys_data, num_classes=10):\n",
    "  ys_data = tf.one_hot(ys_data, depth=num_classes)  # One-hot encode labels\n",
    "  return tf.data.Dataset.from_tensor_slices((xs_data, ys_data)) \\\n",
    "    .map(preprocessing_function) \\\n",
    "    .shuffle(buffer_size=1000) \\\n",
    "    .batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c34f6305",
   "metadata": {},
   "outputs": [],
   "source": [
    "My_model = keras.Sequential([\n",
    "    keras.layers.Reshape(target_shape=(28 * 28,), input_shape=(28, 28)),  # Flatten the input\n",
    "    keras.layers.Dense(units=128, activation='relu'),                    # Hidden layer : A layer with 128 neurons and the ReLU activation function.\n",
    "    keras.layers.Dense(units=10, activation='softmax')                   # Output layer :  Outputs 10 probabilities (one for each class).\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0723e729",
   "metadata": {},
   "outputs": [],
   "source": [
    "My_model.compile(optimizer='adam', \n",
    "              loss=tf.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b1ac5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julie\\Anaconda3\\lib\\site-packages\\keras\\backend.py:5535: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits, \"Softmax\", \"categorical_crossentropy\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 2s 3ms/step - loss: 0.4267 - accuracy: 0.8804 - val_loss: 0.2684 - val_accuracy: 0.9531\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 0.2351 - accuracy: 0.9324 - val_loss: 0.1278 - val_accuracy: 0.9688\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.1853 - accuracy: 0.9461 - val_loss: 0.2348 - val_accuracy: 0.9219\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.1510 - accuracy: 0.9548 - val_loss: 0.0680 - val_accuracy: 0.9844\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.1290 - accuracy: 0.9621 - val_loss: 0.0761 - val_accuracy: 0.9844\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.1189 - accuracy: 0.9644 - val_loss: 0.0654 - val_accuracy: 0.9844\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.1145 - accuracy: 0.9657 - val_loss: 0.0638 - val_accuracy: 0.9844\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0852 - accuracy: 0.9744 - val_loss: 0.1329 - val_accuracy: 0.9531\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 1s 2ms/step - loss: 0.0833 - accuracy: 0.9751 - val_loss: 0.1190 - val_accuracy: 0.9688\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.0793 - accuracy: 0.9779 - val_loss: 0.1013 - val_accuracy: 0.9688\n"
     ]
    }
   ],
   "source": [
    "x_train_data, y_train_data = preprocessing_function(x_train_data, y_train_data)\n",
    "x_val_data, y_val_data = preprocessing_function(x_val_data, y_val_data)\n",
    "dataset_training = func_creating_dataset(x_train_data, y_train_data)\n",
    "dataset_val = func_creating_dataset(x_val_data, y_val_data)\n",
    "\n",
    "history = My_model.fit(\n",
    "    dataset_training.repeat(), \n",
    "    epochs=10, \n",
    "    steps_per_epoch=500,\n",
    "    validation_data=dataset_val.repeat(), \n",
    "    validation_steps=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a6ae456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n",
      "[[9.5148579e-08 9.9942940e-01 2.8472205e-06 ... 4.8948603e-04\n",
      "  1.8148268e-05 1.3798307e-06]\n",
      " [4.6911840e-03 1.9052950e-05 9.8011816e-01 ... 1.2639826e-04\n",
      "  6.5454934e-03 2.0796365e-06]\n",
      " [2.6399639e-05 1.0127126e-01 3.4872196e-03 ... 2.2641344e-01\n",
      "  5.2142940e-02 6.0692632e-01]\n",
      " ...\n",
      " [1.3946428e-09 3.4469583e-09 9.5857700e-08 ... 8.1286535e-06\n",
      "  5.3719202e-07 1.6596310e-05]\n",
      " [2.1738954e-06 1.5406041e-08 1.4747343e-05 ... 5.7460386e-07\n",
      "  5.6087923e-10 8.9607357e-07]\n",
      " [2.0581897e-10 3.7931938e-10 6.9305464e-09 ... 9.9999964e-01\n",
      "  1.8453565e-11 3.4490213e-07]]\n"
     ]
    }
   ],
   "source": [
    "Make_predictions = My_model.predict(dataset_val)\n",
    "print(Make_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1e658b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1026 - accuracy: 0.9687\n",
      "Test Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = My_model.evaluate(dataset_val)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "110d4036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1000 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def plot_predictions(images, labels, predictions, num_images=5):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.imshow(images[i], cmap=plt.cm.binary)\n",
    "        plt.title(f\"True: {np.argmax(labels[i])}, Pred: {np.argmax(predictions[i])}\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "plot_predictions(x_val_data, y_val_data, Make_predictions, num_images=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "074dd34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e1b544",
   "metadata": {},
   "source": [
    "# Exercise 4 : Forward Propagation Calculation\n",
    "\n",
    "In this exercise, you will manually compute the forward propagation of a simple neural network that predicts house prices based on:\n",
    "\n",
    "   - Square Footage (x₁)\n",
    "   - Number of Bedrooms (x₂)\n",
    "\n",
    "We will calculate the output using the following given values:\n",
    "\n",
    "Input Values:\\\n",
    "    x₁ = 2000 (Square Footage)\\\n",
    "    x₂ = 3 (Number of Bedrooms)\\\n",
    "Initial Weights:\\\n",
    "    w₁ = 0.5 (Weight for Square Footage)\\\n",
    "    w₂ = 0.7 (Weight for Bedrooms)\\\n",
    "Bias: b = 50,000\\\n",
    "Activation Function: ReLU (Rectified Linear Unit)\n",
    "\n",
    "   1. Calculate the output value “z” before activation.\n",
    "   2. Apply the ReLU function to compute the final prediction.\n",
    "   3. Interpret the result: What is the predicted house price?\n",
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93415109",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = 2000\n",
    "x2 = 3\n",
    "w1 = 0.5\n",
    "w2 = 0.7\n",
    "b = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81d4b065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51002.1\n"
     ]
    }
   ],
   "source": [
    "z = x1*w1 + x2*w2 + b\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af8dacc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51002.1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(0,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16a663b",
   "metadata": {},
   "source": [
    "The predicted house price is $51002.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb47182",
   "metadata": {},
   "source": [
    "### Exercise 5 : Implementing Forward and Backward Propagation in Python\n",
    "\n",
    "You will code a simple neural network that performs forward propagation and backpropagation for a regression problem (predicting exam scores based on study hours).\n",
    "\n",
    "\n",
    "   1. Run the code and observe how the weights and bias update.\n",
    "   2. Explain why updating weights using gradient descent reduces the error.\n",
    "   3. Modify the initial weights or learning rate and see how it affects learning.\n",
    "\n",
    "_________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03db2378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Prediction: 36.4\n",
      "Loss: 1180.98\n",
      "Updated Weights: [ 2.544 39.18 ]\n",
      "Updated Bias: 10.486\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize input data (features)\n",
    "x = np.array([4, 80])  # 4 hours studied, previous test score: 80\n",
    "\n",
    "# Initialize weights and bias\n",
    "w = np.array([0.6, 0.3])  # Initial weights\n",
    "b = 10  # Initial bias\n",
    "\n",
    "# Forward Propagation\n",
    "def forward_propagation(x, w, b):\n",
    "    z = np.dot(x, w) + b  # Weighted sum\n",
    "    return z  # Linear activation (No ReLU here, it's a regression task)\n",
    "\n",
    "# Compute prediction\n",
    "y_pred = forward_propagation(x, w, b)\n",
    "y_true = 85  # Actual exam score\n",
    "\n",
    "# Compute Loss (Mean Squared Error)\n",
    "loss = 0.5 * (y_true - y_pred) ** 2\n",
    "\n",
    "# Compute Gradients\n",
    "grad_w = -(y_true - y_pred) * x  # Partial derivatives with respect to weights\n",
    "grad_b = -(y_true - y_pred)  # Partial derivative with respect to bias\n",
    "\n",
    "# Update Weights and Bias\n",
    "learning_rate = 0.01\n",
    "w_new = w - learning_rate * grad_w\n",
    "b_new = b - learning_rate * grad_b\n",
    "\n",
    "# Print Results\n",
    "print(\"Initial Prediction:\", y_pred)\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Updated Weights:\", w_new)\n",
    "print(\"Updated Bias:\", b_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b4ea13",
   "metadata": {},
   "source": [
    "The weights were originally w1 = 0.6 and w2 = 0.3 and they changed to w1 = 2.544 and 39.18. The bias changed from 10 to 10.486.\n",
    "\n",
    "Gradient descent is an optimization algorithm that adjusts the model's parameters (weights and bias) to minimize the loss function. By subtracting the gradients (scaled by the learning rate), it moves towards the minimum of the loss, reducing error with each iteration and gradually converging to the optimal parameters.\n",
    "\n",
    "Now I will change the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2b717c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Prediction: 2420.0\n",
      "Loss: 2726112.5\n",
      "Updated Weights: [  -90.9 -1838. ]\n",
      "Updated Bias: -13.350000000000001\n"
     ]
    }
   ],
   "source": [
    "# Initialize input data (features)\n",
    "x = np.array([4, 80])  # 4 hours studied, previous test score: 80\n",
    "\n",
    "# Initialize weights and bias\n",
    "w = np.array([2.5, 30])  # Initial weights\n",
    "b = 10  # Initial bias\n",
    "\n",
    "# Forward Propagation\n",
    "def forward_propagation(x, w, b):\n",
    "    z = np.dot(x, w) + b  # Weighted sum\n",
    "    return z  # Linear activation (No ReLU here, it's a regression task)\n",
    "\n",
    "# Compute prediction\n",
    "y_pred = forward_propagation(x, w, b)\n",
    "y_true = 85  # Actual exam score\n",
    "\n",
    "# Compute Loss (Mean Squared Error)\n",
    "loss = 0.5 * (y_true - y_pred) ** 2\n",
    "\n",
    "# Compute Gradients\n",
    "grad_w = -(y_true - y_pred) * x  # Partial derivatives with respect to weights\n",
    "grad_b = -(y_true - y_pred)  # Partial derivative with respect to bias\n",
    "\n",
    "# Update Weights and Bias\n",
    "learning_rate = 0.01\n",
    "w_new = w - learning_rate * grad_w\n",
    "b_new = b - learning_rate * grad_b\n",
    "\n",
    "# Print Results\n",
    "print(\"Initial Prediction:\", y_pred)\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Updated Weights:\", w_new)\n",
    "print(\"Updated Bias:\", b_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4734a487",
   "metadata": {},
   "source": [
    "Now the Weights changed to w1 = -90.9 and w2 = -1838 and the bias to -13.35!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
