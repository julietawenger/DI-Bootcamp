{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1993af95",
   "metadata": {},
   "source": [
    "# Exercises XP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256cd9f0",
   "metadata": {},
   "source": [
    "1. Install Required Libraries\n",
    "\n",
    "Ensure you have the necessary libraries installed, including gensim, spacy, torch, and scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42a5915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module, LSTM, Linear, Dropout, MSELoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset\n",
    "from torch import Tensor, save, load\n",
    "import gensim\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeed39f9",
   "metadata": {},
   "source": [
    "2. Load and Preprocess the Dataset\n",
    "\n",
    "    Download the stock market dataset.\n",
    "    \n",
    "    Drop unnecessary columns and create a target column for the next dayâ€™s closing price.\n",
    "    \n",
    "    Normalize the dataset using MinMaxScaler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc4642b",
   "metadata": {},
   "source": [
    "The Dataset is not the correct one. I'll use the one we used in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2d5419",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('all_stocks_2006-01-01_to_2018-01-01.csv', index_col='Date', parse_dates=['Date'])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bfba65",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(columns=['Name', 'Volume'])\n",
    "\n",
    "dataset['Target'] = dataset['Close'].shift(-1) # To create the Target column\n",
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c823ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dataset.columns:\n",
    "    print(dataset[i].dtype) # I want to check if I can scale the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762d95fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = sc.fit_transform(dataset) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8fecce",
   "metadata": {},
   "source": [
    "3. Prepare the Dataset for Training\n",
    "\n",
    "    Split the dataset into training, validation, and testing sets.\n",
    "    \n",
    "    Create a custom PyTorch Dataset class to handle the data.\n",
    "    \n",
    "    Use DataLoader to create iterable datasets for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61396932",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(dataset, test_size=0.2, shuffle=False)\n",
    "train_data, val_data  = train_test_split(train_data, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4691f068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create features and targets\n",
    "def create_features_and_targets(data, lookback=60):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(lookback, len(data)):\n",
    "        X.append(data.iloc[i-lookback:i][['Open', 'High', 'Low', 'Close']].values)\n",
    "        y.append(data.iloc[i]['Target'])\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Prepare features and targets for training, validation, and testing sets\n",
    "lookback = 60  # Number of previous days to look at for prediction\n",
    "\n",
    "X_train, y_train = create_features_and_targets(train_data, lookback)\n",
    "X_val, y_val = create_features_and_targets(val_data, lookback)\n",
    "X_test, y_test = create_features_and_targets(test_data, lookback)\n",
    "\n",
    "# Convert the features and targets to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
